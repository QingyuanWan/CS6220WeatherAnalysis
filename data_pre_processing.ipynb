{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of the dataset:\n",
      "                 station state  latitude  longitude  elevation      date  \\\n",
      "0           GUAM INTL AP    GU   13.4836   144.7961       77.4  20170312   \n",
      "1        ROOSEVELT ROADS    PR   18.2550   -65.6408       10.1  20170404   \n",
      "2        ROOSEVELT ROADS    PR   18.2550   -65.6408       10.1  20170420   \n",
      "3  SAN JUAN L M MARIN AP    PR   18.4325   -66.0108        2.7  20170120   \n",
      "4  SAN JUAN L M MARIN AP    PR   18.4325   -66.0108        2.7  20170217   \n",
      "\n",
      "    TMIN   TMAX   TAVG      AWND   WDF5       WSF5  SNOW  SNWD  PRCP  \n",
      "0  71.06  87.08  80.06  4.473880  360.0  21.027236   0.0   0.0   0.0  \n",
      "1  77.00  86.00    NaN  8.947760  360.0  23.040482   NaN   NaN   0.0  \n",
      "2    NaN    NaN    NaN  8.500372  360.0  21.922012   NaN   NaN   0.0  \n",
      "3  69.08  82.04    NaN  3.355410  360.0  17.000744   0.0   0.0   0.0  \n",
      "4  73.04  87.08    NaN  4.697574  360.0  19.908766   0.0   0.0   0.0  \n",
      "\n",
      "Removed rows with missing dates. Remaining rows: 416937\n",
      "Removed rows with missing geographic information. Remaining rows: 416937\n",
      " Removed rows with missing temperature data. Remaining rows: 71978\n",
      "Removed duplicate `station` + `date` records. Remaining rows: 71978\n",
      "\n",
      "Cleaned dataset saved as 'cleaned_weather.csv'\n",
      "\n",
      " Preview of the cleaned dataset:\n",
      "                 station state  latitude  longitude  elevation       date  \\\n",
      "0           GUAM INTL AP    GU   13.4836   144.7961       77.4 2017-03-12   \n",
      "7   KALISPELL GLACIER AP    MT   48.3042  -114.2636      901.3 2017-02-07   \n",
      "8   KALISPELL GLACIER AP    MT   48.3042  -114.2636      901.3 2017-03-30   \n",
      "9   KALISPELL GLACIER AP    MT   48.3042  -114.2636      901.3 2017-06-22   \n",
      "10  KALISPELL GLACIER AP    MT   48.3042  -114.2636      901.3 2017-07-25   \n",
      "\n",
      "     TMIN   TMAX   TAVG      AWND   WDF5       WSF5     SNOW       SNWD  \\\n",
      "0   71.06  87.08  80.06  4.473880  360.0  21.027236  0.00000   0.000000   \n",
      "7   -0.76  22.10  13.64  3.802798  360.0  14.092722  0.11811  22.047256   \n",
      "8   37.04  53.96  44.24  4.026492  360.0  19.908766  0.00000   0.000000   \n",
      "9   35.96  73.04  59.72  3.579104  360.0  19.013990  0.00000   0.000000   \n",
      "10  53.06  87.08  71.60  6.039738  360.0  21.922012  0.00000   0.000000   \n",
      "\n",
      "        PRCP  \n",
      "0   0.000000  \n",
      "7   0.000000  \n",
      "8   0.070866  \n",
      "9   0.000000  \n",
      "10  0.000000  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CS 6220 Final Project\n",
    "\n",
    "Data pre-processing step.\n",
    "This script cleans the raw weather dataset (weather-1.csv) for data mining use.\n",
    "\n",
    "Steps:\n",
    "1. Load the CSV file\n",
    "2. Remove rows with missing dates or important geographic info\n",
    "3. Convert date format to YYYY-MM-DD\n",
    "4. Remove rows with missing weather data (TMIN, TMAX, etc.)\n",
    "5. Drop duplicate records based on station and date\n",
    "6. Save the cleaned data to 'cleaned_weather.csv'\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"./data/weather-1.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preview the dataset\n",
    "print(\"Preview of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Drop rows with missing date values\n",
    "df = df.dropna(subset=[\"date\"])\n",
    "print(f\"\\nRemoved rows with missing dates. Remaining rows: {df.shape[0]}\")\n",
    "\n",
    "# Convert date format (YYYYMMDD â†’ YYYY-MM-DD)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "# Drop rows with missing critical geographical information\n",
    "geo_columns = [\"state\", \"latitude\", \"longitude\", \"elevation\"]\n",
    "df = df.dropna(subset=geo_columns)\n",
    "print(f\"Removed rows with missing geographic information. Remaining rows: {df.shape[0]}\")\n",
    "\n",
    "# Drop rows with missing temperature data (TMIN, TMAX, TAVG, AWND, WSF5 and PRCP)\n",
    "temp_columns = [\"TMIN\", \"TMAX\", \"TAVG\", \"AWND\", \"WSF5\",\"PRCP\"]\n",
    "df = df.dropna(subset=temp_columns)\n",
    "print(f\" Removed rows with missing temperature data. Remaining rows: {df.shape[0]}\")\n",
    "\n",
    "# Remove duplicate records based on `station` and `date`\n",
    "df = df.drop_duplicates(subset=[\"station\", \"date\"])\n",
    "print(f\"Removed duplicate `station` + `date` records. Remaining rows: {df.shape[0]}\")\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv(\"./data/cleaned_weather.csv\", index=False)\n",
    "print(\"\\nCleaned dataset saved as 'cleaned_weather.csv'\")\n",
    "\n",
    "print(\"\\n Preview of the cleaned dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
